description: TDS Virtual TA Project Sample (but not the actual evaluation) Questions

providers:

  - id: local
    config:
      url: http://127.0.0.1:8000/query
      method: POST
      headers:
        Content-Type: application/json
      body:
        question: "{{ prompt }}"
        image: "{{ image | default(null) }}"
      transformResponse: json

  - id: aiproxy
    config:
      url: https://aiproxy.sanand.workers.dev/openai/v1/chat/completions
      method: POST
      headers:
        Content-Type: application/json
        Authorization: "Bearer eyJhbGciOiJIUzI1NiJ9.eyJlbWFpbCI6InBhcmFkb3hAc3R1ZHkuaWl0bS5hYy5pbiJ9.8syemsA9TDKiwGfvHmf2Zlg8Tv4L7uuRkXqYAyfRBxs"
      body:
        model: "gpt-4o-mini"
        messages:
          - role: system
            content: >-
              You are an evaluator that checks if an output meets specific criteria.
              Analyze the output based on the given rubric and respond with a JSON
              object containing {"reason":"your analysis","score": number between
              0.0 and 1.0,"pass":true/false}.
          - role: user
            content: >-
              Output to evaluate: {{ output }}

              Rubric: {{ rubric }}
        temperature: 0
      transformResponse: json

defaultTest:
  options:
    provider:
      id: local

tests:
  - name: clarify-model-use
    vars:
      prompt: >-
        The question asks to use gpt-3.5-turbo-0125 model but the ai-proxy
        provided by Anand sir only supports gpt-4o-mini. So should we just use
        gpt-4o-mini or use the OpenAI API for gpt3.5 turbo?
      image: project-tds-virtual-ta-q1.webp
    assert:
      - type: llm-rubric
        transform: output.answer
        value: Clarifies use of gpt-3.5-turbo-0125 not gpt-4o-mini
      - type: contains
        transform: JSON.stringify(output.links)
        value: https://discourse.onlinedegree.iitm.ac.in/t/ga5-question-8-clarification/155939

  - name: ga4-bonus-dashboard
    vars:
      prompt: >-
        If a student scores 10/10 on GA4 as well as a bonus, how would it appear
        on the dashboard?
    assert:
      - type: llm-rubric
        transform: output.answer
        value: Mentions the dashboard showing "110"
      - type: contains
        transform: JSON.stringify(output.links)
        value: https://discourse.onlinedegree.iitm.ac.in/t/ga4-data-sourcing-discussion-thread-tds-jan-2025/165959

  - name: docker-vs-podman
    vars:
      prompt: >-
        I know Docker but have not used Podman before. Should I use Docker for
        this course?
    assert:
      - type: llm-rubric
        transform: output.answer
        value: Recommends Podman for the course
      - type: llm-rubric
        transform: output.answer
        value: Mentions that Docker is acceptable
      - type: contains
        transform: JSON.stringify(output.links)
        value: https://tds.s-anand.net/#/docker

  - name: tds-exam-date
    vars:
      prompt: When is the TDS Sep 2025 end-term exam?
    assert:
      - type: llm-rubric
        transform: output.answer
        value: Says it doesn't know (since this information is not available yet)

  - name: partial-marks-json
    vars:
      prompt: >-
        Will there be partial marks for incorrect JSON responses in GA4?
    assert:
      - type: llm-rubric
        transform: output.answer
        value: Clarifies partial marking criteria

  - name: podman-logs
    vars:
      prompt: How do I access the Podman container logs for debugging errors?
    assert:
      - type: llm-rubric
        transform: output.answer
        value: Describes command or method for retrieving Podman logs

  - name: ga5-pass-threshold
    vars:
      prompt: What is the minimum score required in GA5 to pass the course?
    assert:
      - type: llm-rubric
        transform: output.answer
        value: Mentions the threshold clearly (e.g. 40%)

  - name: gpu-requirement
    vars:
      prompt: Does the TDS course require GPU for local model testing?
    assert:
      - type: llm-rubric
        transform: output.answer
        value: Clarifies whether GPU is mandatory or optional

  - name: proxy-403
    vars:
      prompt: What should I do if my proxy returns a 403 Forbidden error?
    assert:
      - type: llm-rubric
        transform: output.answer
        value: Suggests checking headers or authentication settings

  - name: third-party-apis
    vars:
      prompt: Is it okay to use third-party APIs in my evaluation module?
    assert:
      - type: llm-rubric
        transform: output.answer
        value: Mentions if external APIs are allowed or not

  - name: exam-open-closed
    vars:
      prompt: Will the TDS end-term be open book or closed book?
    assert:
      - type: llm-rubric
        transform: output.answer
        value: Specifies the exam type (open/closed book)

  - name: citations-mandatory
    vars:
      prompt: >-
        Do we need to include citations for all sources used in our GA submission?
    assert:
      - type: llm-rubric
        transform: output.answer
        value: States whether citations are mandatory or optional

  - name: test-local-setup
    vars:
      prompt: How can I test my local setup to match the evaluation environment?
    assert:
      - type: llm-rubric
        transform: output.answer
        value: Recommends ways to simulate or match the evaluation container setup

  - name: hardcode-answers
    vars:
      prompt: >-
        Is it okay to hard-code answers for specific inputs if I explain why?
    assert:
      - type: llm-rubric
        transform: output.answer
        value: Explains whether hardcoding is permitted and under what justification

  - name: internet-access
    vars:
      prompt: >-
        Will the evaluation script run with internet access or in a sandboxed
        environment?
    assert:
      - type: llm-rubric
        transform: output.answer
        value: Clearly mentions whether internet access is available during evaluation

evaluations:
  - name: rubric-evaluation
    options:
      provider:
        id: aiproxy
    assert:
      - type: is-json
        value:
          type: object
          required: [reason, score, pass]
          properties:
            reason:
              type: string
            score:
              type: number
            pass:
              type: boolean

writeLatestResults: true
commandLineOptions:
  cache: false